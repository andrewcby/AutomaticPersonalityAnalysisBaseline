{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random, csv, time, os, pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import optimize\n",
    "from scipy.stats import bernoulli\n",
    "from scipy.io import savemat\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions\n",
    " * **mle(w, pairs)**\n",
    " \n",
    " Calculate the MLE of w.\n",
    " \n",
    " Due to the fact that optimize.minimize only takes 1 input, here the pair information is imported from global variable.\n",
    " \n",
    " \n",
    " * **gradient(w,pairs)**\n",
    " \n",
    " Calculate the gradient of MLE. \n",
    " \n",
    " Returns a numpy array with value of gradient.\n",
    " \n",
    " \n",
    " * **hessian(w, pairs)**\n",
    " \n",
    " Calculate the hessian of MLE. \n",
    " \n",
    " Returns a numpy matrix with value of hessian.\n",
    " \n",
    " \n",
    " * **compare_rank(video_score, results, verbose=False, hist=False)**\n",
    " \n",
    " Compute the true rankings and rankings from results. \n",
    " \n",
    " `verbose` will output with columns: Result Order, True Order, Result Score, Ture Score\n",
    "    \n",
    " `hist` will output a histogram\n",
    "\n",
    "\n",
    " * **init_graph(num_nodes, num_edges, reference_matrix=None)**\n",
    " \n",
    " Marc's method of generating pairs\n",
    " \n",
    " \n",
    " * **matching_func(param, video_score, w_hat)**\n",
    "\n",
    " Function used to calculate L2 norm of v and w_star. Used to find a and b.\n",
    " Here param is [a, b]\n",
    "\n",
    "    \n",
    " * **regularized_vector(video_score,w_hat)**\n",
    "\n",
    " Function to generate vector v after using matching_func to find optimal a and b\n",
    " \n",
    " \n",
    " \n",
    " * **performance_isabelle(video_score, video_num, w_hat)**\n",
    "\n",
    " Performance evaluation using method proposed by Isabelle.\n",
    " \n",
    " \n",
    " * **performance_nihar(video_score, video_num, w_hat)**\n",
    "\n",
    " Performance evaluation using method proposed by Nihar.\n",
    " \n",
    " \n",
    " * **noise_generation(video_score, pair)**\n",
    "\n",
    " Generate a decision of whether to flip, using proability from normal distribution and then Bernoulli to decide whether to flip\n",
    " \n",
    " \n",
    " * **sigmoid(x)**\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mle(w, pairs):    \n",
    "    out = 1      \n",
    "    for pair in pairs:\n",
    "        if pair[0] == -1 or pair[1] == -1:\n",
    "            continue\n",
    "        out *= 1/(1+np.exp(-w[pair[0]] + w[pair[1]]))   \n",
    "    return -np.log(out)\n",
    "\n",
    "def gradient(w,pairs):\n",
    "    grad = []\n",
    "    for i in range(len(w)):\n",
    "        gradient = 0\n",
    "\n",
    "        for pair in pairs:\n",
    "            if i == pair[0]:\n",
    "                out = -1\n",
    "            elif i == pair[1]:\n",
    "                out = 1  \n",
    "            else:\n",
    "                continue\n",
    "            gradient -= out / (1/(np.exp(w[pair[1]]-w[pair[0]])) +1 )\n",
    "\n",
    "        grad.append(-gradient)\n",
    "        \n",
    "    return np.array(grad)\n",
    "\n",
    "def hessian(w, pairs):\n",
    "    hessian = np.zeros((300, 300))\n",
    "    for pair in pairs:\n",
    "        exp_0 = np.exp(w[pair[1]]-w[pair[0]])\n",
    "        hess = exp_0/(1+exp_0)**2\n",
    "        hessian[pair[0], pair[1]] = hess\n",
    "        hessian[pair[1], pair[0]] = hess\n",
    "        \n",
    "    return hessian\n",
    "\n",
    "# def compare_rank(video_score, results, verbose=False, hist=False):\n",
    "#     true_order = np.array(video_score).argsort()\n",
    "#     true_ranks = true_order.argsort()\n",
    "\n",
    "#     temp_o = np.array(results).argsort()\n",
    "#     temp_r = temp_o.argsort()\n",
    "\n",
    "#     resolution = 0.1\n",
    "#     video_score_results = np.round(np.array(results)/resolution)*resolution\n",
    "    \n",
    "#     if verbose:\n",
    "#         print 'Result Order \\t True Order \\t Result Score \\t Ture Score'\n",
    "#         for i in range(len(temp_r)):\n",
    "#             print temp_r[i], '\\t\\t', true_ranks[i], '\\t\\t', video_score_results[i], '\\t\\t', video_score[i]\n",
    "            \n",
    "#     if hist:\n",
    "#         diff = np.abs(temp_r - true_ranks)\n",
    "#         plt.hist(diff, alpha=0.5)\n",
    "\n",
    "        \n",
    "def compare_rank(video_score, results, hist=False):\n",
    "    scale_and_bias = np.dot(np.linalg.pinv(np.concatenate((results[:, None],\n",
    "                                                           np.ones((len(results), 1))), axis=1)), video_score)\n",
    "\n",
    "    difference = np.abs(video_score - (results * scale_and_bias[0] + scale_and_bias[1]))\n",
    "    return difference\n",
    "        \n",
    "\n",
    "def init_graph(num_nodes, num_edges, reference_matrix=None):\n",
    "    # If the number of edges is lower than num_nodes-1, raise error\n",
    "    if num_edges < num_nodes:\n",
    "        raise AttributeError('The number of edges must be >= num_nodes')\n",
    "\n",
    "    # Define list of neighbors (with initial circular connection)\n",
    "    neighbors = [[i-1, i+1] for i in range(num_nodes)]\n",
    "    neighbors[0][0], neighbors[-1][1] = num_nodes-1, 0\n",
    "\n",
    "    # Define list of node indices, maximum degree and number of placed nodes\n",
    "    nodes, max_degree, num_placed = range(num_nodes), int(np.ceil((2.0 * num_edges) / num_nodes)), num_nodes\n",
    "\n",
    "    def rewire_pairs(p0, p1):\n",
    "        # Select existing pair\n",
    "        ph1 = np.random.choice(num_nodes)\n",
    "        ph2 = neighbors[ph1][np.random.choice(len(neighbors[ph1]))]\n",
    "        while p0 in neighbors[ph2] or p1 in neighbors[ph1] or p0 in [ph1, ph2] or p1 in [ph1, ph2]:\n",
    "            ph1 = np.random.choice(num_nodes)\n",
    "            ph2 = neighbors[ph1][np.random.choice(len(neighbors[ph1]))]\n",
    "\n",
    "        # Rewire with current pair\n",
    "        neighbors[ph1].remove(ph2)\n",
    "        neighbors[ph2].remove(ph1)\n",
    "        neighbors[ph1].append(p1)\n",
    "        neighbors[p1].append(ph1)\n",
    "        neighbors[ph2].append(p0)\n",
    "        neighbors[p0].append(ph2)\n",
    "\n",
    "    # Start placing random edges\n",
    "    ct = 0\n",
    "    while num_placed < num_edges:\n",
    "        # If only one node left, rewire with existing pair\n",
    "        if len(nodes) == 1:\n",
    "            rewire_pairs(nodes[0], nodes[0])\n",
    "            num_placed += 1\n",
    "            continue\n",
    "\n",
    "        # Sample random pair of nodes\n",
    "        pair = np.random.choice(nodes, size=2, replace=False)\n",
    "\n",
    "        # If pair already connected, do rewiring\n",
    "        if pair[0] in neighbors[pair[1]]:\n",
    "            if ct < 100:\n",
    "                ct += 1\n",
    "                continue\n",
    "            rewire_pairs(pair[0], pair[1])\n",
    "            num_placed += 1\n",
    "\n",
    "        # Else, place edge between nodes\n",
    "        else:\n",
    "            neighbors[pair[0]].append(pair[1])\n",
    "            neighbors[pair[1]].append(pair[0])\n",
    "            num_placed += 1\n",
    "\n",
    "        ct = 0\n",
    "\n",
    "        # If max degree reached for first node, remove from sampling list\n",
    "        if len(neighbors[pair[0]]) >= max_degree:\n",
    "            nodes.remove(pair[0])\n",
    "\n",
    "        # If max degree reached for second node, remove from sampling list\n",
    "        if len(neighbors[pair[1]]) >= max_degree:\n",
    "            nodes.remove(pair[1])\n",
    "\n",
    "    # Return pairs\n",
    "    return [(\n",
    "        (i, j) if reference_matrix is None or reference_matrix[i] > reference_matrix[j] else (j, i)\n",
    "    ) for i, il in enumerate(neighbors) for j in sorted(il) if i < j]\n",
    "\n",
    "\n",
    "def matching_func(param, video_score, w_hat):\n",
    "    return np.linalg.norm(video_score - param[0]*np.array(w_hat) - param[1])\n",
    "\n",
    "\n",
    "def regularized_vector(video_score,w_hat):\n",
    "    coeff = optimize.minimize(matching_func, [0, 0], args=(video_score, w_hat))\n",
    "\n",
    "    a = coeff['x'][0]\n",
    "    b = coeff['x'][1]\n",
    "    v = a*np.array(w_hat)+b\n",
    "    return v\n",
    "\n",
    "def performance_isabelle(video_score, video_num, w_hat):\n",
    "    epsilon = 0.0001\n",
    "    error = 0\n",
    "    v = regularized_vector(video_score,w_hat)\n",
    "\n",
    "    true_order = np.array(video_score).argsort()\n",
    "\n",
    "    what = [ w_hat[i] for i in true_order]\n",
    "    wstar = [ video_score[i] for i in true_order]\n",
    "\n",
    "    for i in range(video_num-2):\n",
    "        error += np.abs((wstar[i+1]-wstar[i])/(wstar[i+2]-wstar[i]+epsilon)-\n",
    "                        (what[i+1]-what[i])/(what[i+2]-what[i]+epsilon))\n",
    "    \n",
    "    return error\n",
    "\n",
    "def performance_nihar(video_score, w_hat):\n",
    "    v = regularized_vector(video_score,w_hat)\n",
    "    return np.linalg.norm(video_score - v)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def noise_generation(video_score, pair):\n",
    "    difference = video_score[pair[0]] - video_score[pair[1]]\n",
    "    p = sigmoid(difference)*(1-sigmoid(difference))\n",
    "    decision = bernoulli.rvs(p,size=1)\n",
    "\n",
    "    return decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation\n",
    "The cell below generates data for $video\\_num$ videos, calculates all possible pairs and stores in $pairs\\_truth$ and $total_pairs$ is the number of pairs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# video_nums = [625,1250,2500,5000,10000,20000]\n",
    "# num_edges_pct = [0.01,0.1,1,10,100]\n",
    "\n",
    "video_nums = [5000]\n",
    "num_edges_pct = [0.01,0.1,1,10]\n",
    "\n",
    "for iteration in range(7):\n",
    "    for video_num in video_nums:\n",
    "        for num_edge_pct in num_edges_pct:\n",
    "\n",
    "            num_edge = int(num_edge_pct*video_num*np.log(video_num))\n",
    "\n",
    "            if num_edge < video_num:\n",
    "                num_edge = video_num\n",
    "            if num_edge > video_num*(video_num-1)/2:\n",
    "                num_edge = video_num*(video_num-1)/2\n",
    "\n",
    "            video_score = np.random.uniform(-5,5,video_num)\n",
    "            resolution = 0.1\n",
    "            video_score = np.round(video_score/resolution)*resolution\n",
    "\n",
    "            w = np.ones(video_num)\n",
    "            print video_num, num_edge\n",
    "            # test_pairs = [pairs_truth[i] for i in random.sample(range(total_pairs),num_edge)]\n",
    "            test_pairs = init_graph(video_num, num_edge, video_score)\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            res = optimize.minimize(mle, w, \n",
    "                                    method='Newton-CG',\n",
    "                                    jac=gradient,\n",
    "                                    args=(test_pairs,),\n",
    "                                    tol = 10,\n",
    "                                    options={'disp': False})\n",
    "\n",
    "            filename = 'result/'+ str(video_num)+'_at_'+str(num_edge)+'_iter_'+str(iteration)+'.p'\n",
    "#             print float(time.time() - start_time)\n",
    "            pickle.dump( dict({'x':res.x, 'video_score':video_score}), open( filename, \"wb\" ) )\n",
    "            print  'Time on Iteration %d with Video Number %d and edges %.2f : %.1f seconds' %(iteration, video_num, num_edge_pct, float(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = dict({'x':1, 'video':5})\n",
    "pickle.dump(a, open('a.p',\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print a['video']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
